{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 records.\n"
     ]
    }
   ],
   "source": [
    "#加载数据集\n",
    "import json\n",
    "\n",
    "data = []\n",
    "with open('../data/crag_data_200.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "print(f\"Loaded {len(data)} records.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录是: /home/u2021213565/jupyterlab/RAG2406/RAG_HBX\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 获取并打印当前工作目录\n",
    "current_working_directory = os.getcwd()\n",
    "print(f\"当前工作目录是: {current_working_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "local_model_path = \"./model/checkpoint-15000\"\n",
    "\n",
    "class MyEmbeddingFunction(EmbeddingFunction):\n",
    "    def __init__(self, model_path: str):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        inputs = self.tokenizer(input, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        # Assuming the embeddings are in the last hidden state and taking the mean pooling\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "        return embeddings.tolist()\n",
    "\n",
    "\n",
    "# 使用你的bge-small-en-v1.5模型创建自定义嵌入函数\n",
    "my_embedding_function = MyEmbeddingFunction(model_path=local_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建数据库\n",
    "import chromadb\n",
    "\n",
    "# Initialize Chroma client\n",
    "# client = chromadb.Client()\n",
    "client = chromadb.PersistentClient(path=\"./chroma_pipeline\")\n",
    "# Create a new collection\n",
    "collection = client.create_collection(name=\"collection_embedding\", embedding_function=my_embedding_function)\n",
    "# collection = client.create_collection('crag_documents')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=64, chunk_overlap=2, add_start_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records: 100%|██████████| 200/200 [00:01<00:00, 118.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been inserted into Chroma.\n"
     ]
    }
   ],
   "source": [
    "# 准备并插入数据到Chroma\n",
    "from tqdm import tqdm\n",
    "\n",
    "documents = []\n",
    "metadatas = []\n",
    "ids = []\n",
    "\n",
    "for i, record in enumerate(tqdm(data, desc=\"Processing records\")):\n",
    "    query = record[\"query\"]\n",
    "    answer = record[\"answer\"]\n",
    "    search_results = record[\"search_results\"]\n",
    "    \n",
    "    # 创建一个包含query和answer的文档字符串，并添加search_results的内容\n",
    "    # document = query + \" \" + answer + \" \" + \" \".join([result[\"page_snippet\"] for result in search_results])\n",
    "    text = ''.join([result[\"page_snippet\"] for result in search_results])\n",
    "    doc=text_splitter.create_documents([text])\n",
    "    all_splits = text_splitter.split_documents(doc)\n",
    "    \n",
    "    # 遍历所有分块并分别添加到相应的列表中\n",
    "    for j, split in enumerate(all_splits):\n",
    "        documents.append(split.page_content)\n",
    "        metadatas.append({\n",
    "            \"query\": query,\n",
    "            \"answer\": answer,\n",
    "            \"split_index\": j\n",
    "        })\n",
    "        ids.append(f\"doc_{i}_split_{j}\")\n",
    "\n",
    "# 向集合中添加文档\n",
    "collection.add(\n",
    "    documents=documents,  # 自动处理分词、嵌入和索引\n",
    "    metadatas=metadatas,  # 可以根据这些元数据进行过滤\n",
    "    ids=ids  # 每个文档的唯一标识\n",
    ")\n",
    "\n",
    "print(\"Data has been inserted into Chroma.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 relevant documents:\n",
      "Is gold or silver the best choice for investing? We compare the\n",
      "considering silver as an investment option then you would be\n",
      "considering silver as an investment option then you would be\n",
      "investment option.Though, as an investment, silver is not as\n",
      "as an investment, silver is not as popular as gold, it is in\n",
      "Context:\n",
      "Is gold or silver the best choice for investing? We compare the\n",
      "considering silver as an investment option then you would be\n",
      "considering silver as an investment option then you would be\n",
      "investment option.Though, as an investment, silver is not as\n",
      "as an investment, silver is not as popular as gold, it is in\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试用例\n",
    "\n",
    "# 查询\n",
    "query = \"which is a better investment, gold or silver, when considering long-term return?\"\n",
    "\n",
    "# 执行查询，先筛选出包含query的所有文本块，再获取最相似的三个结果\n",
    "results = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=5,\n",
    "    where={\"query\": query},  # 筛选包含该query的所有文本块\n",
    ")\n",
    "\n",
    "print(\"Top 3 relevant documents:\")\n",
    "context = \"\"\n",
    "for result in results['documents']:\n",
    "    for doc in result:  # 遍历列表中的每一个文档\n",
    "        print(doc)\n",
    "        context += doc + \"\\n\"\n",
    "\n",
    "print(\"Context:\")\n",
    "print(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# 设置百度API密钥\n",
    "API_KEY = \"r3eHPr2Da9rJa1yJpd5qCGy3\"\n",
    "SECRET_KEY = \"Wyi1aOmWcjt70roUhQS4v2GbOvmfGXHn\"\n",
    "\n",
    "def get_access_token():\n",
    "    \"\"\"\n",
    "    使用 API Key，Secret Key 获取access_token\n",
    "    \"\"\"\n",
    "    url = f\"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={API_KEY}&client_secret={SECRET_KEY}\"\n",
    "    response = requests.post(url)\n",
    "    return response.json().get(\"access_token\")\n",
    "\n",
    "def call_baidu_chat_api(query, context):\n",
    "    access_token = get_access_token()\n",
    "    url = f\"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/yi_34b_chat?access_token={access_token}\"\n",
    "    payload = json.dumps({\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Answer in 2 to 3 sentences. Context: {context} Question: {query}\",\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, data=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Baidu API:\n",
      "{'id': 'as-2vuzgypb0s', 'object': 'chat.completion', 'created': 1719303448, 'result': 'The first president of the United States was George Washington. He served two terms as president from 1789 to 1797. Washington is often referred to as the \"Father of His Country\" for his pivotal role in the founding of the United States. Before becoming president, he served as the commander-in-chief of the Continental Army during the American Revolutionary War and presided over the convention that drafted the U.S. Constitution.', 'is_truncated': False, 'need_clear_history': False, 'usage': {'prompt_tokens': 162, 'completion_tokens': 94, 'total_tokens': 256}}\n",
      "The first president of the United States was George Washington. He served two terms as president from 1789 to 1797. Washington is often referred to as the \"Father of His Country\" for his pivotal role in the founding of the United States. Before becoming president, he served as the commander-in-chief of the Continental Army during the American Revolutionary War and presided over the convention that drafted the U.S. Constitution.\n"
     ]
    }
   ],
   "source": [
    "# 测试用例\n",
    "query = \"Who was the first president of the United States?\"\n",
    "context = \"\"\"\n",
    "The first president of the United States was George Washington. He served two terms as president from 1789 to 1797. Washington is often referred to as the \"Father of His Country\" for his pivotal role in the founding of the United States. Before becoming president, he served as the commander-in-chief of the Continental Army during the American Revolutionary War and presided over the convention that drafted the U.S. Constitution.\n",
    "\"\"\"\n",
    "# 调用百度API获取答案\n",
    "response = call_baidu_chat_api(query, context)\n",
    "print(\"Response from Baidu API:\")\n",
    "print(response)\n",
    "if \"result\" in response and response[\"result\"]:\n",
    "    print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_database(query):\n",
    "    results = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=5,\n",
    "    where={\"query\": query},  # 筛选包含该query的所有文本块\n",
    "                        )\n",
    "    context = \"\"\n",
    "    for result in results['documents']:\n",
    "        for doc in result:  # 遍历列表中的每一个文档\n",
    "            context += doc + \"\\n\"\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   0%|          | 1/200 [00:04<15:01,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: which is a better investment, gold or silver, when considering long-term return?\n",
      "Answer: gold\n",
      "Response from Baidu API: When considering long-term return, gold is generally considered the better investment option compared to silver. Gold has a history of maintaining its value over time and is often used as a hedge against inflation. While silver can also be a good investment, it is more volatile and subject to more price fluctuations than gold, making it a riskier choice for long-term investment purposes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   1%|          | 2/200 [00:07<11:33,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: which country is the largest gold producer?\n",
      "Answer: china\n",
      "Response from Baidu API: According to the provided context, the largest gold producing country in the world is China. It produced 403 metric tons of gold in 2012, followed by Australia and Russia.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   2%|▏         | 3/200 [00:11<12:51,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: what is the name of priyanka chopra's fashion line?\n",
      "Answer: invalid question\n",
      "Response from Baidu API: I'm sorry, but I don't have information about Priyanka Chopra having her own fashion line. She is known for her fashion sense and has been a prominent figure in the entertainment industry, but I'm not aware of her having a specific brand or line of clothing. If you have any other questions, I'll be happy to help!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   2%|▏         | 4/200 [00:14<11:18,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: who has won more atp singles titles, roger federer or rafael nadal?\n",
      "Answer: rafael nadal has won more atp singles titles than roger federer, with 86 titles compared to federer's 82.\n",
      "Response from Baidu API: Roger Federer has won more ATP singles titles than Rafael Nadal. Federer has won 103 ATP titles in his career, while Nadal has won 85 ATP titles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   2%|▎         | 5/200 [00:18<11:48,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: who was responsible for initiating the construction of the badshahi mosque?\n",
      "Answer: aurangzeb\n",
      "Response from Baidu API: The construction of the Badshahi Mosque was initiated by Emperor Aurangzeb, the sixth Mughal Emperor, who reigned from 1658 to 1707. He was responsible for commissioning the mosque, which was built between 1671 and 1673.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   3%|▎         | 6/200 [00:23<13:09,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: what is the price of bitcoin when it launch in 2015?\n",
      "Answer: invalid question\n",
      "Response from Baidu API: The price of Bitcoin when it launched in 2015 was under $5. However, it's important to note that the question seems to be confused about the launch date of Bitcoin. Bitcoin was first introduced in 2009, not 2015. The price of Bitcoin in 2009 was very different from what it was in 2015.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   3%|▎         | 6/200 [00:25<13:41,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: how much rings does steve kerr hold?\n",
      "Answer: kerr is a nine-time nba champion\n",
      "Response from Baidu API: Steve Kerr holds 9 rings in total, 5 of them as a player and 4 as a coach.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#测试用例，先问它个5回\n",
    "for i, record in enumerate(tqdm(data, desc=\"Processing records\")):\n",
    "    query = record[\"query\"]\n",
    "    answer = record[\"answer\"]\n",
    "    search_results = record[\"search_results\"]\n",
    "    context = query_database(query)\n",
    "    response = call_baidu_chat_api(query, context)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    pred = response['result']\n",
    "    print(f\"Response from Baidu API: {pred}\")\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i, record in enumerate(tqdm(data, desc=\"Processing records\")):\n",
    "    query = record[\"query\"]\n",
    "    answer = record[\"answer\"]\n",
    "    search_results = record[\"search_results\"]\n",
    "    context = query_database(query)\n",
    "    response = call_baidu_chat_api(query, context)\n",
    "    pred = response['result']\n",
    "    result.append(json.dumps({'query': query, 'answer': answer, 'pred': pred}, ensure_ascii=False) + '\\n')\n",
    "with open(\"../data/baidu_chat_results.jsonl\", 'w', encoding='utf-8') as f:\n",
    "    f.write(''.join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_processing(data, target_file='./baidu_chat_results.jsonl'):\n",
    "    # 检查目标文件的目录是否存在，不存在则创建\n",
    "    target_dir = os.path.dirname(target_file)\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    # 读取已有文件的行数，确定从哪一行开始继续处理\n",
    "    if os.path.exists(target_file):\n",
    "        with open(target_file, 'r', encoding='utf-8') as f:\n",
    "            processed_lines = len(f.readlines())\n",
    "    else:\n",
    "        processed_lines = 0\n",
    "\n",
    "    result = []\n",
    "    for i, record in enumerate(tqdm(data[processed_lines:], desc=\"Processing records\", initial=processed_lines, total=len(data))):\n",
    "        query = record[\"query\"]\n",
    "        answer = record[\"answer\"]\n",
    "        search_results = record[\"search_results\"]\n",
    "        context = query_database(query)\n",
    "        response = call_baidu_chat_api(query, context)\n",
    "        if 'result' in response:\n",
    "            pred = response['result']\n",
    "        else:\n",
    "            print(f\"Missing 'result' key in response for query: {query}\")\n",
    "            pred = None\n",
    "        result.append(json.dumps({'query': query, 'answer': answer, 'pred': pred}, ensure_ascii=False) + '\\n')\n",
    "\n",
    "        # 每处理一条记录就立即写入文件，防止中途出错数据丢失\n",
    "        with open(target_file, 'a', encoding='utf-8') as f:\n",
    "            f.write(result[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing records:   4%|▍         | 8/200 [00:31<12:27,  3.90s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "continue_processing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
